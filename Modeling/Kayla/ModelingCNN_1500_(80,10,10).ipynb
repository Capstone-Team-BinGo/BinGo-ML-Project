{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-G1RgBaQNpb",
        "outputId": "743fd608-3fd6-439a-8a1a-c5f9562aae24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '1AEenvsEPa35bHgnqGpcXK8hqbp1iV6Ya'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', 'dataset_final_split.zip', quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "yR_NoXvdRm_R",
        "outputId": "79b47656-3f12-4491-ac45-c0f6f190b542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1AEenvsEPa35bHgnqGpcXK8hqbp1iV6Ya\n",
            "From (redirected): https://drive.google.com/uc?id=1AEenvsEPa35bHgnqGpcXK8hqbp1iV6Ya&confirm=t&uuid=b34d1261-e798-45e3-8996-df8d9e1b5ede\n",
            "To: /content/dataset_final_split.zip\n",
            "100%|██████████| 175M/175M [00:01<00:00, 120MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset_final_split.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "wVsfn3m2BARs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('dataset_final_split.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')"
      ],
      "metadata": {
        "id": "4FL91FDiRtkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Pindahkan folder\n",
        "shutil.move('dataset/content/data_final_split', 'data_final_split')\n",
        "\n",
        "# Hapus folder 'dataset/content'\n",
        "shutil.rmtree('dataset')"
      ],
      "metadata": {
        "id": "kGKr0hueRxdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = 'data_final_split'\n",
        "splits = ['train', 'val', 'test']\n",
        "\n",
        "for split in splits:\n",
        "    print(f\"\\n=== {split.upper()} ===\")\n",
        "    split_dir = os.path.join(base_dir, split)\n",
        "    for class_name in os.listdir(split_dir):\n",
        "        class_dir = os.path.join(split_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            n_files = len(os.listdir(class_dir))\n",
        "            print(f\"{class_name}: {n_files} gambar\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cu-jU8wA9ms",
        "outputId": "de4afb5a-1a9b-4ee6-cb1b-caaf285b7ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRAIN ===\n",
            "Daun: 1200 gambar\n",
            "Kardus: 1200 gambar\n",
            "Baterai: 1200 gambar\n",
            "Sterofom: 1200 gambar\n",
            "Logam: 1200 gambar\n",
            "Masker: 1200 gambar\n",
            "Lampu: 1200 gambar\n",
            "Plastik: 1200 gambar\n",
            "Elektronik: 1200 gambar\n",
            "Pakaian: 1200 gambar\n",
            "Sampah Makanan: 1200 gambar\n",
            "Kaca: 1200 gambar\n",
            "Kertas: 1200 gambar\n",
            "\n",
            "=== VAL ===\n",
            "Daun: 150 gambar\n",
            "Kardus: 150 gambar\n",
            "Baterai: 150 gambar\n",
            "Sterofom: 150 gambar\n",
            "Logam: 150 gambar\n",
            "Masker: 150 gambar\n",
            "Lampu: 150 gambar\n",
            "Plastik: 150 gambar\n",
            "Elektronik: 150 gambar\n",
            "Pakaian: 150 gambar\n",
            "Sampah Makanan: 150 gambar\n",
            "Kaca: 150 gambar\n",
            "Kertas: 150 gambar\n",
            "\n",
            "=== TEST ===\n",
            "Daun: 150 gambar\n",
            "Kardus: 150 gambar\n",
            "Baterai: 150 gambar\n",
            "Sterofom: 150 gambar\n",
            "Logam: 150 gambar\n",
            "Masker: 150 gambar\n",
            "Lampu: 150 gambar\n",
            "Plastik: 150 gambar\n",
            "Elektronik: 150 gambar\n",
            "Pakaian: 150 gambar\n",
            "Sampah Makanan: 150 gambar\n",
            "Kaca: 150 gambar\n",
            "Kertas: 150 gambar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELING"
      ],
      "metadata": {
        "id": "UoOHax68S2WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Augmentasi data untuk training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Hanya rescale untuk validasi\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Buat data generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iMDwW1nSoqs",
        "outputId": "db330ee3-9c9c-4d93-bae4-02e87803930e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15600 images belonging to 13 classes.\n",
            "Found 1950 images belonging to 13 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_generator.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uga0iZplBxct",
        "outputId": "b2c599df-af47-48f4-d4b9-852d060fcd46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Baterai': 0, 'Daun': 1, 'Elektronik': 2, 'Kaca': 3, 'Kardus': 4, 'Kertas': 5, 'Lampu': 6, 'Logam': 7, 'Masker': 8, 'Pakaian': 9, 'Plastik': 10, 'Sampah Makanan': 11, 'Sterofom': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 1"
      ],
      "metadata": {
        "id": "ikSTrNj84YmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Model CNN sederhana\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callback\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "]\n",
        "\n",
        "# Training model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kr60ZCXS460",
        "outputId": "4342bf66-f7f0-45f1-fac6-ec16f4abf41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 396ms/step - accuracy: 0.1776 - loss: 2.4765 - val_accuracy: 0.4005 - val_loss: 1.8192 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 381ms/step - accuracy: 0.3733 - loss: 1.8839 - val_accuracy: 0.4297 - val_loss: 1.6531 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 381ms/step - accuracy: 0.4132 - loss: 1.7650 - val_accuracy: 0.4682 - val_loss: 1.5912 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 385ms/step - accuracy: 0.4390 - loss: 1.6893 - val_accuracy: 0.4862 - val_loss: 1.5090 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 383ms/step - accuracy: 0.4527 - loss: 1.6408 - val_accuracy: 0.5179 - val_loss: 1.4767 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 381ms/step - accuracy: 0.4811 - loss: 1.5556 - val_accuracy: 0.5374 - val_loss: 1.3966 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 380ms/step - accuracy: 0.4958 - loss: 1.5235 - val_accuracy: 0.5487 - val_loss: 1.4033 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 385ms/step - accuracy: 0.5067 - loss: 1.4832 - val_accuracy: 0.5436 - val_loss: 1.4363 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 388ms/step - accuracy: 0.5186 - loss: 1.4352 - val_accuracy: 0.5713 - val_loss: 1.3460 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 392ms/step - accuracy: 0.5262 - loss: 1.4313 - val_accuracy: 0.5692 - val_loss: 1.3488 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 392ms/step - accuracy: 0.5360 - loss: 1.4050 - val_accuracy: 0.5923 - val_loss: 1.2749 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 394ms/step - accuracy: 0.5430 - loss: 1.3825 - val_accuracy: 0.5785 - val_loss: 1.3470 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 391ms/step - accuracy: 0.5499 - loss: 1.3573 - val_accuracy: 0.5913 - val_loss: 1.2653 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 388ms/step - accuracy: 0.5644 - loss: 1.3162 - val_accuracy: 0.5764 - val_loss: 1.3330 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 383ms/step - accuracy: 0.5762 - loss: 1.2803 - val_accuracy: 0.5744 - val_loss: 1.2814 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.5799 - loss: 1.2588\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 387ms/step - accuracy: 0.5799 - loss: 1.2588 - val_accuracy: 0.5687 - val_loss: 1.3220 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 380ms/step - accuracy: 0.6078 - loss: 1.1918 - val_accuracy: 0.6210 - val_loss: 1.1676 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 380ms/step - accuracy: 0.6167 - loss: 1.1464 - val_accuracy: 0.6277 - val_loss: 1.1490 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 382ms/step - accuracy: 0.6193 - loss: 1.1296 - val_accuracy: 0.6292 - val_loss: 1.1612 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 388ms/step - accuracy: 0.6348 - loss: 1.1074 - val_accuracy: 0.6149 - val_loss: 1.2153 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.6329 - loss: 1.0867\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 386ms/step - accuracy: 0.6329 - loss: 1.0867 - val_accuracy: 0.6179 - val_loss: 1.1692 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 381ms/step - accuracy: 0.6427 - loss: 1.0594 - val_accuracy: 0.6272 - val_loss: 1.1688 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 378ms/step - accuracy: 0.6500 - loss: 1.0430 - val_accuracy: 0.6482 - val_loss: 1.1087 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 383ms/step - accuracy: 0.6593 - loss: 1.0247 - val_accuracy: 0.6338 - val_loss: 1.1249 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 382ms/step - accuracy: 0.6615 - loss: 1.0122 - val_accuracy: 0.6497 - val_loss: 1.0959 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 383ms/step - accuracy: 0.6568 - loss: 1.0011 - val_accuracy: 0.6436 - val_loss: 1.1135 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 380ms/step - accuracy: 0.6645 - loss: 1.0016 - val_accuracy: 0.6554 - val_loss: 1.0879 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 381ms/step - accuracy: 0.6662 - loss: 0.9910 - val_accuracy: 0.6472 - val_loss: 1.0968 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 383ms/step - accuracy: 0.6747 - loss: 0.9717 - val_accuracy: 0.6431 - val_loss: 1.1044 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.6711 - loss: 0.9694\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 378ms/step - accuracy: 0.6711 - loss: 0.9695 - val_accuracy: 0.6472 - val_loss: 1.0907 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 376ms/step - accuracy: 0.6847 - loss: 0.9338 - val_accuracy: 0.6610 - val_loss: 1.0877 - learning_rate: 1.2500e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 376ms/step - accuracy: 0.6838 - loss: 0.9431 - val_accuracy: 0.6544 - val_loss: 1.0964 - learning_rate: 1.2500e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 373ms/step - accuracy: 0.6741 - loss: 0.9397 - val_accuracy: 0.6415 - val_loss: 1.1212 - learning_rate: 1.2500e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 372ms/step - accuracy: 0.6898 - loss: 0.9130 - val_accuracy: 0.6626 - val_loss: 1.0739 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 379ms/step - accuracy: 0.6858 - loss: 0.9149 - val_accuracy: 0.6441 - val_loss: 1.1133 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 377ms/step - accuracy: 0.6898 - loss: 0.9034 - val_accuracy: 0.6559 - val_loss: 1.1014 - learning_rate: 1.2500e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.6896 - loss: 0.9089\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 379ms/step - accuracy: 0.6896 - loss: 0.9089 - val_accuracy: 0.6641 - val_loss: 1.0967 - learning_rate: 1.2500e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 377ms/step - accuracy: 0.6917 - loss: 0.9085 - val_accuracy: 0.6703 - val_loss: 1.0604 - learning_rate: 6.2500e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 382ms/step - accuracy: 0.7054 - loss: 0.8751 - val_accuracy: 0.6626 - val_loss: 1.1066 - learning_rate: 6.2500e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 378ms/step - accuracy: 0.6921 - loss: 0.8980 - val_accuracy: 0.6646 - val_loss: 1.0802 - learning_rate: 6.2500e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.7082 - loss: 0.8657\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 380ms/step - accuracy: 0.7082 - loss: 0.8658 - val_accuracy: 0.6579 - val_loss: 1.1070 - learning_rate: 6.2500e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 379ms/step - accuracy: 0.7004 - loss: 0.8577 - val_accuracy: 0.6631 - val_loss: 1.0916 - learning_rate: 3.1250e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 381ms/step - accuracy: 0.7062 - loss: 0.8675 - val_accuracy: 0.6708 - val_loss: 1.0549 - learning_rate: 3.1250e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 384ms/step - accuracy: 0.7014 - loss: 0.8755 - val_accuracy: 0.6574 - val_loss: 1.0798 - learning_rate: 3.1250e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 379ms/step - accuracy: 0.7043 - loss: 0.8683 - val_accuracy: 0.6626 - val_loss: 1.0786 - learning_rate: 3.1250e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.7110 - loss: 0.8576\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 379ms/step - accuracy: 0.7109 - loss: 0.8576 - val_accuracy: 0.6621 - val_loss: 1.0771 - learning_rate: 3.1250e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 381ms/step - accuracy: 0.7064 - loss: 0.8738 - val_accuracy: 0.6631 - val_loss: 1.0842 - learning_rate: 1.5625e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 379ms/step - accuracy: 0.7134 - loss: 0.8467 - val_accuracy: 0.6662 - val_loss: 1.0790 - learning_rate: 1.5625e-05\n",
            "Epoch 48: early stopping\n",
            "Restoring model weights from the end of the best epoch: 43.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi pakai test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSXVcBb-THbk",
        "outputId": "c8c5d1c6-d764-4a83-b3bd-80f9334add8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1950 images belonging to 13 classes.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6508 - loss: 1.1031\n",
            "Test Accuracy: 68.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 2"
      ],
      "metadata": {
        "id": "anNou_GVp2tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Definisi model CNN\n",
        "model2 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi model dengan RMSprop (default learning rate)\n",
        "model2.compile(\n",
        "    optimizer=RMSprop(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callback\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "]\n",
        "\n",
        "# Training\n",
        "history = model2.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unm1yMthp4m1",
        "outputId": "0338e0a7-96da-4d06-ed70-38ff38f725f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 367ms/step - accuracy: 0.2026 - loss: 2.5106 - val_accuracy: 0.4169 - val_loss: 1.7622 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 372ms/step - accuracy: 0.3864 - loss: 1.8761 - val_accuracy: 0.4718 - val_loss: 1.5974 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 374ms/step - accuracy: 0.4320 - loss: 1.7234 - val_accuracy: 0.4969 - val_loss: 1.5355 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 372ms/step - accuracy: 0.4582 - loss: 1.6558 - val_accuracy: 0.5421 - val_loss: 1.4398 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 376ms/step - accuracy: 0.4820 - loss: 1.5930 - val_accuracy: 0.5518 - val_loss: 1.4639 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 383ms/step - accuracy: 0.5038 - loss: 1.5472 - val_accuracy: 0.5656 - val_loss: 1.3574 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 376ms/step - accuracy: 0.5128 - loss: 1.4950 - val_accuracy: 0.5656 - val_loss: 1.3701 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 373ms/step - accuracy: 0.5258 - loss: 1.4825 - val_accuracy: 0.5749 - val_loss: 1.3595 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.5422 - loss: 1.4138\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 370ms/step - accuracy: 0.5422 - loss: 1.4139 - val_accuracy: 0.5405 - val_loss: 1.4678 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 372ms/step - accuracy: 0.5877 - loss: 1.2826 - val_accuracy: 0.5944 - val_loss: 1.2973 - learning_rate: 5.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 3"
      ],
      "metadata": {
        "id": "v7z6ylQvRXfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Model CNN yang dioptimasi\n",
        "model3 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi model\n",
        "model3.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Callback\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1)\n",
        "]\n",
        "\n",
        "# Training model\n",
        "history3 = model3.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "qLz8OlfWRY1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 4"
      ],
      "metadata": {
        "id": "oAGYMR5Gb2hF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Model CNN lebih dalam (4 Conv2D layers)\n",
        "model4 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi model\n",
        "model4.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Callback\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1)\n",
        "]\n",
        "\n",
        "# Training model\n",
        "history4 = model4.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "3Z3rzqPSb4tl",
        "outputId": "ed320df2-3406-46bf-bba0-55403ddc8023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 412ms/step - accuracy: 0.1237 - loss: 8.3179 - val_accuracy: 0.1154 - val_loss: 2.5433 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 384ms/step - accuracy: 0.0961 - loss: 2.5423 - val_accuracy: 0.0872 - val_loss: 2.5544 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 386ms/step - accuracy: 0.0918 - loss: 2.5460 - val_accuracy: 0.1287 - val_loss: 2.4802 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 392ms/step - accuracy: 0.0953 - loss: 2.5356 - val_accuracy: 0.1128 - val_loss: 2.4911 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 388ms/step - accuracy: 0.0974 - loss: 2.5294 - val_accuracy: 0.1287 - val_loss: 2.4521 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m 89/488\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 387ms/step - accuracy: 0.0977 - loss: 2.5170"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2c36d7556e98>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m history4 = model4.fit(\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL Tata"
      ],
      "metadata": {
        "id": "ptOjK1cU8wGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Contoh input size, sesuaikan kalau berbeda\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 13\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    RandomRotation(0.1),\n",
        "    RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "model3 = models.Sequential([\n",
        "    layers.InputLayer(input_shape=input_shape),\n",
        "    data_augmentation,\n",
        "\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    # Fully Connected\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7oE6lL1R8v2o",
        "outputId": "0ee409f8-1fee-4927-8b42-3710506b0886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m51,380,736\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │         \u001b[38;5;34m6,669\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">51,380,736</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,669</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,678,253\u001b[0m (197.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,678,253</span> (197.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,676,333\u001b[0m (197.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,676,333</span> (197.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1)\n",
        "\n",
        "history = model3.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmaOm-JR81zl",
        "outputId": "712c2ccd-4fc9-442f-eb2f-b7f22c91f174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - accuracy: 0.2535 - loss: 2.7320"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 470ms/step - accuracy: 0.2536 - loss: 2.7314 - val_accuracy: 0.3185 - val_loss: 2.0293 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 465ms/step - accuracy: 0.3977 - loss: 1.8892 - val_accuracy: 0.3462 - val_loss: 2.0575 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 469ms/step - accuracy: 0.4483 - loss: 1.6865 - val_accuracy: 0.3164 - val_loss: 2.1676 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - accuracy: 0.4783 - loss: 1.5588\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 467ms/step - accuracy: 0.4783 - loss: 1.5588 - val_accuracy: 0.3005 - val_loss: 2.5706 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 466ms/step - accuracy: 0.5323 - loss: 1.4014 - val_accuracy: 0.5364 - val_loss: 1.4280 - learning_rate: 3.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 464ms/step - accuracy: 0.5553 - loss: 1.3230 - val_accuracy: 0.4995 - val_loss: 1.6043 - learning_rate: 3.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 464ms/step - accuracy: 0.5760 - loss: 1.2942 - val_accuracy: 0.5031 - val_loss: 1.6684 - learning_rate: 3.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 0.5887 - loss: 1.2470\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 463ms/step - accuracy: 0.5887 - loss: 1.2470 - val_accuracy: 0.5138 - val_loss: 1.5346 - learning_rate: 3.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 467ms/step - accuracy: 0.6146 - loss: 1.1621 - val_accuracy: 0.4933 - val_loss: 1.5898 - learning_rate: 9.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 466ms/step - accuracy: 0.6306 - loss: 1.1219 - val_accuracy: 0.5538 - val_loss: 1.4194 - learning_rate: 9.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 464ms/step - accuracy: 0.6492 - loss: 1.0623 - val_accuracy: 0.5374 - val_loss: 1.4839 - learning_rate: 9.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 479ms/step - accuracy: 0.6393 - loss: 1.0873 - val_accuracy: 0.4538 - val_loss: 1.9334 - learning_rate: 9.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 467ms/step - accuracy: 0.6477 - loss: 1.0548 - val_accuracy: 0.5713 - val_loss: 1.4016 - learning_rate: 9.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 465ms/step - accuracy: 0.6624 - loss: 1.0301 - val_accuracy: 0.5421 - val_loss: 1.4352 - learning_rate: 9.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 465ms/step - accuracy: 0.6666 - loss: 1.0092 - val_accuracy: 0.5595 - val_loss: 1.4123 - learning_rate: 9.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - accuracy: 0.6765 - loss: 0.9789\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 468ms/step - accuracy: 0.6765 - loss: 0.9789 - val_accuracy: 0.5579 - val_loss: 1.4263 - learning_rate: 9.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 464ms/step - accuracy: 0.6777 - loss: 0.9559 - val_accuracy: 0.5149 - val_loss: 1.5618 - learning_rate: 2.7000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 465ms/step - accuracy: 0.6910 - loss: 0.9374 - val_accuracy: 0.5462 - val_loss: 1.4803 - learning_rate: 2.7000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi pakai test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loss, accuracy = model3.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgrgIm-DIMjs",
        "outputId": "acd69b8d-bbec-4e14-d7de-e8807996f452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1950 images belonging to 13 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.5634 - loss: 1.5036\n",
            "Test Accuracy: 59.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# package matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot akurasi\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "4R_j66pFINW8",
        "outputId": "3c6bb738-f143-47f8-d635-26cb10f97f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# --- Parameter Dasar ---\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 13\n",
        "\n",
        "# --- Data Augmentation Layer ---\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomContrast(0.2)\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "# --- Fungsi Membangun Model CNN dari Awal (model6) ---\n",
        "def build_model6_from_scratch(input_shape, num_classes, data_augmentation_layer):\n",
        "    inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "    # Augmentasi data hanya aktif saat training\n",
        "    x = data_augmentation_layer(inputs)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', name=\"conv1a\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn1a\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu1a\")(x)\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', name=\"conv1b\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn1b\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu1b\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "    x = layers.Dropout(0.25, name=\"drop1\")(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', name=\"conv2a\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn2a\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu2a\")(x)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', name=\"conv2b\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn2b\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu2b\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "    x = layers.Dropout(0.25, name=\"drop2\")(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', name=\"conv3a\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn3a\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu3a\")(x)\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', name=\"conv3b\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn3b\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu3b\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool3\")(x)\n",
        "    x = layers.Dropout(0.3, name=\"drop3\")(x)\n",
        "\n",
        "    # Fully Connected Head\n",
        "    x = layers.Flatten(name=\"flatten\")(x)\n",
        "    x = layers.Dense(512, name=\"dense1\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn_dense1\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu_dense1\")(x)\n",
        "    x = layers.Dropout(0.5, name=\"drop_dense1\")(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', name=\"output_layer\")(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name=\"model6_from_scratch\")\n",
        "    return model\n",
        "\n",
        "model6 = build_model6_from_scratch(input_shape, num_classes, data_augmentation)\n",
        "\n",
        "# --- Kompilasi Model ---\n",
        "initial_learning_rate = 1e-3\n",
        "optimizer = optimizers.Adam(learning_rate=initial_learning_rate)\n",
        "\n",
        "model6.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model6.summary()\n",
        "\n",
        "# --- Callbacks ---\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=7,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks_list = [early_stopping, reduce_lr]\n",
        "\n",
        "# --- Training Model ---\n",
        "epochs = 30\n",
        "\n",
        "print(\"Memulai training model6 (from scratch)...\")\n",
        "history = model6.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks_list\n",
        ")"
      ],
      "metadata": {
        "id": "--kDKDYwRKcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3931967c-f034-4470-ae64-2af207f6e236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model6_from_scratch\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model6_from_scratch\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1a (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn1a (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu1a (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1b (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn1b (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu1b (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop1 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2a (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn2a (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu2a (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2b (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn2b (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu2b (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop2 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3a (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn3a (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu3a (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3b (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn3b (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu3b (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop3 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m51,380,736\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn_dense1 (\u001b[38;5;33mBatchNormalization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu_dense1 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop_dense1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │         \u001b[38;5;34m6,669\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn1a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu1a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn1b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu1b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn2a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu2a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn2b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu2b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn3a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu3a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn3b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu3b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">51,380,736</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,669</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,678,253\u001b[0m (197.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,678,253</span> (197.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,676,333\u001b[0m (197.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,676,333</span> (197.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai training model6 (from scratch)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 529ms/step - accuracy: 0.2833 - loss: 2.3140 - val_accuracy: 0.3549 - val_loss: 2.0314 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 527ms/step - accuracy: 0.3999 - loss: 1.8195 - val_accuracy: 0.4021 - val_loss: 1.8967 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 518ms/step - accuracy: 0.4445 - loss: 1.6629 - val_accuracy: 0.4472 - val_loss: 1.6547 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 516ms/step - accuracy: 0.4753 - loss: 1.5714 - val_accuracy: 0.3000 - val_loss: 2.6176 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 523ms/step - accuracy: 0.4965 - loss: 1.5296 - val_accuracy: 0.4595 - val_loss: 1.6146 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 518ms/step - accuracy: 0.5087 - loss: 1.4675 - val_accuracy: 0.4354 - val_loss: 1.6907 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 517ms/step - accuracy: 0.5248 - loss: 1.4103 - val_accuracy: 0.4974 - val_loss: 1.4865 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 518ms/step - accuracy: 0.5356 - loss: 1.4089 - val_accuracy: 0.4313 - val_loss: 1.9432 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 523ms/step - accuracy: 0.5468 - loss: 1.3548 - val_accuracy: 0.5205 - val_loss: 1.4876 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 519ms/step - accuracy: 0.5593 - loss: 1.3282 - val_accuracy: 0.5846 - val_loss: 1.2309 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 518ms/step - accuracy: 0.5782 - loss: 1.2727 - val_accuracy: 0.5795 - val_loss: 1.2819 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 524ms/step - accuracy: 0.5734 - loss: 1.2630 - val_accuracy: 0.4149 - val_loss: 1.9158 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 519ms/step - accuracy: 0.5843 - loss: 1.2464 - val_accuracy: 0.4092 - val_loss: 2.1128 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 529ms/step - accuracy: 0.6001 - loss: 1.2110 - val_accuracy: 0.5985 - val_loss: 1.2021 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 529ms/step - accuracy: 0.6081 - loss: 1.1818 - val_accuracy: 0.4913 - val_loss: 1.5958 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 513ms/step - accuracy: 0.6098 - loss: 1.1713 - val_accuracy: 0.5113 - val_loss: 1.6994 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 513ms/step - accuracy: 0.6114 - loss: 1.1367 - val_accuracy: 0.5851 - val_loss: 1.3105 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 530ms/step - accuracy: 0.6335 - loss: 1.1151 - val_accuracy: 0.5846 - val_loss: 1.3029 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 521ms/step - accuracy: 0.6294 - loss: 1.1037 - val_accuracy: 0.6082 - val_loss: 1.1768 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 518ms/step - accuracy: 0.6369 - loss: 1.0937 - val_accuracy: 0.5692 - val_loss: 1.4026 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 520ms/step - accuracy: 0.6335 - loss: 1.0864 - val_accuracy: 0.6333 - val_loss: 1.0866 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 518ms/step - accuracy: 0.6538 - loss: 1.0484 - val_accuracy: 0.6015 - val_loss: 1.1897 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 519ms/step - accuracy: 0.6545 - loss: 1.0326 - val_accuracy: 0.5097 - val_loss: 1.7711 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 527ms/step - accuracy: 0.6603 - loss: 1.0115 - val_accuracy: 0.5908 - val_loss: 1.2552 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 521ms/step - accuracy: 0.6582 - loss: 1.0150 - val_accuracy: 0.5738 - val_loss: 1.3320 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 522ms/step - accuracy: 0.6729 - loss: 0.9769 - val_accuracy: 0.6287 - val_loss: 1.1147 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 521ms/step - accuracy: 0.6824 - loss: 0.9461 - val_accuracy: 0.5933 - val_loss: 1.2974 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.6668 - loss: 0.9780\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 518ms/step - accuracy: 0.6668 - loss: 0.9780 - val_accuracy: 0.6077 - val_loss: 1.2921 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 521ms/step - accuracy: 0.6982 - loss: 0.8940 - val_accuracy: 0.6703 - val_loss: 0.9868 - learning_rate: 2.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 518ms/step - accuracy: 0.7184 - loss: 0.8527 - val_accuracy: 0.6862 - val_loss: 0.9578 - learning_rate: 2.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 30.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi pakai test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loss, accuracy = model6.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9187jEGyi9z",
        "outputId": "e034b344-af20-4be1-83f4-3dd39d1d693a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1950 images belonging to 13 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.6459 - loss: 1.1121\n",
            "Test Accuracy: 69.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# --- Parameter Dasar ---\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 13\n",
        "\n",
        "# --- Data Augmentation Layer ---\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomContrast(0.2)\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "# --- Fungsi Membangun Model CNN dengan Depthwise Separable Conv (model7) ---\n",
        "def build_model7_depthwise_sep(input_shape, num_classes, data_augmentation_layer):\n",
        "    inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "    # Augmentasi data aktif saat training\n",
        "    x = data_augmentation_layer(inputs)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.SeparableConv2D(32, (3, 3), padding='same', name=\"sep_conv1a\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn1a\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu1a\")(x)\n",
        "    x = layers.SeparableConv2D(32, (3, 3), padding='same', name=\"sep_conv1b\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn1b\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu1b\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "    x = layers.Dropout(0.25, name=\"drop1\")(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.SeparableConv2D(64, (3, 3), padding='same', name=\"sep_conv2a\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn2a\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu2a\")(x)\n",
        "    x = layers.SeparableConv2D(64, (3, 3), padding='same', name=\"sep_conv2b\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn2b\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu2b\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "    x = layers.Dropout(0.25, name=\"drop2\")(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.SeparableConv2D(128, (3, 3), padding='same', name=\"sep_conv3a\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn3a\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu3a\")(x)\n",
        "    x = layers.SeparableConv2D(128, (3, 3), padding='same', name=\"sep_conv3b\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn3b\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu3b\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool3\")(x)\n",
        "    x = layers.Dropout(0.3, name=\"drop3\")(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = layers.SeparableConv2D(256, (3, 3), padding='same', name=\"sep_conv4a\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn4a\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu4a\")(x)\n",
        "    x = layers.SeparableConv2D(256, (3, 3), padding='same', name=\"sep_conv4b\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn4b\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu4b\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool4\")(x)\n",
        "    x = layers.Dropout(0.35, name=\"drop4\")(x)\n",
        "\n",
        "    # Fully Connected Head\n",
        "    x = layers.Flatten(name=\"flatten\")(x)\n",
        "    x = layers.Dense(512, name=\"dense1\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn_dense1\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu_dense1\")(x)\n",
        "    x = layers.Dropout(0.5, name=\"drop_dense1\")(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', name=\"output_layer\")(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name=\"model7_depthwise_sep_cnn\")\n",
        "    return model\n",
        "\n",
        "model7 = build_model7_depthwise_sep(input_shape, num_classes, data_augmentation)\n",
        "\n",
        "# --- Kompilasi Model ---\n",
        "initial_learning_rate = 1e-3\n",
        "optimizer = optimizers.Adam(learning_rate=initial_learning_rate)\n",
        "\n",
        "model7.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model7.summary()\n",
        "\n",
        "# --- Callbacks ---\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=7,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks_list = [early_stopping, reduce_lr]\n",
        "\n",
        "# --- Training Model ---\n",
        "epochs = 30\n",
        "print(\"Memulai training model7 (Depthwise Separable CNN)...\")\n",
        "history = model7.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks_list\n",
        ")"
      ],
      "metadata": {
        "id": "mwCb9yDKGEJj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8319fbf0-7266-4789-e8b3-b078c9fe1538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model7_depthwise_sep_cnn\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model7_depthwise_sep_cnn\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv1a (\u001b[38;5;33mSeparableConv2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m155\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn1a (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu1a (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv1b (\u001b[38;5;33mSeparableConv2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,344\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn1b (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu1b (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop1 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv2a (\u001b[38;5;33mSeparableConv2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m2,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn2a (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu2a (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv2b (\u001b[38;5;33mSeparableConv2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m4,736\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn2b (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu2b (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop2 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv3a (\u001b[38;5;33mSeparableConv2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn3a (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu3a (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv3b (\u001b[38;5;33mSeparableConv2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m17,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn3b (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu3b (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop3 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv4a (\u001b[38;5;33mSeparableConv2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m34,176\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn4a (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu4a (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv4b (\u001b[38;5;33mSeparableConv2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m68,096\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn4b (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu4b (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop4 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m25,690,624\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn_dense1 (\u001b[38;5;33mBatchNormalization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu_dense1 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop_dense1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │         \u001b[38;5;34m6,669\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv1a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">155</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn1a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu1a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv1b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn1b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu1b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv2a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn2a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu2a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv2b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,736</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn2b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu2b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv3a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn3a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu3a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv3b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn3b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu3b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv4a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,176</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn4a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu4a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sep_conv4b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,096</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn4b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu4b (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,624</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,669</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,840,648\u001b[0m (98.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,840,648</span> (98.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,837,704\u001b[0m (98.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,837,704</span> (98.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,944\u001b[0m (11.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,944</span> (11.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai training model7 (Depthwise Separable CNN)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 490ms/step - accuracy: 0.2739 - loss: 2.3948 - val_accuracy: 0.1451 - val_loss: 2.8834 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 484ms/step - accuracy: 0.4223 - loss: 1.7607 - val_accuracy: 0.3231 - val_loss: 2.2860 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 484ms/step - accuracy: 0.4599 - loss: 1.6405 - val_accuracy: 0.2733 - val_loss: 2.7398 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 485ms/step - accuracy: 0.4768 - loss: 1.5631 - val_accuracy: 0.3667 - val_loss: 1.9458 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 484ms/step - accuracy: 0.5093 - loss: 1.4691 - val_accuracy: 0.3774 - val_loss: 2.0857 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 488ms/step - accuracy: 0.5187 - loss: 1.4469 - val_accuracy: 0.3041 - val_loss: 2.8185 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 492ms/step - accuracy: 0.5398 - loss: 1.3909 - val_accuracy: 0.3944 - val_loss: 2.0600 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 498ms/step - accuracy: 0.5588 - loss: 1.3370 - val_accuracy: 0.4949 - val_loss: 1.6242 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 487ms/step - accuracy: 0.5670 - loss: 1.2913 - val_accuracy: 0.3764 - val_loss: 2.1326 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 487ms/step - accuracy: 0.5806 - loss: 1.2639 - val_accuracy: 0.3836 - val_loss: 2.4182 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 488ms/step - accuracy: 0.5942 - loss: 1.2436 - val_accuracy: 0.4733 - val_loss: 1.6601 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 489ms/step - accuracy: 0.5921 - loss: 1.2247 - val_accuracy: 0.2995 - val_loss: 2.8409 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 491ms/step - accuracy: 0.6060 - loss: 1.2030 - val_accuracy: 0.5723 - val_loss: 1.3646 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 490ms/step - accuracy: 0.6192 - loss: 1.1457 - val_accuracy: 0.4897 - val_loss: 1.5592 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 490ms/step - accuracy: 0.6288 - loss: 1.1159 - val_accuracy: 0.5390 - val_loss: 1.4248 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 491ms/step - accuracy: 0.6248 - loss: 1.1129 - val_accuracy: 0.4446 - val_loss: 2.0858 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 487ms/step - accuracy: 0.6296 - loss: 1.1052 - val_accuracy: 0.5913 - val_loss: 1.2998 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 486ms/step - accuracy: 0.6378 - loss: 1.0848 - val_accuracy: 0.4538 - val_loss: 1.9346 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 486ms/step - accuracy: 0.6441 - loss: 1.0528 - val_accuracy: 0.4482 - val_loss: 1.9337 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 487ms/step - accuracy: 0.6536 - loss: 1.0408 - val_accuracy: 0.4938 - val_loss: 1.6085 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 487ms/step - accuracy: 0.6611 - loss: 1.0087 - val_accuracy: 0.4503 - val_loss: 1.8724 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 486ms/step - accuracy: 0.6660 - loss: 1.0127 - val_accuracy: 0.6005 - val_loss: 1.2751 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 485ms/step - accuracy: 0.6745 - loss: 0.9729 - val_accuracy: 0.4190 - val_loss: 2.1645 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 488ms/step - accuracy: 0.6809 - loss: 0.9445 - val_accuracy: 0.6118 - val_loss: 1.2271 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 487ms/step - accuracy: 0.6776 - loss: 0.9488 - val_accuracy: 0.4687 - val_loss: 1.7129 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 485ms/step - accuracy: 0.6888 - loss: 0.9235 - val_accuracy: 0.6462 - val_loss: 1.0738 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 487ms/step - accuracy: 0.6892 - loss: 0.9198 - val_accuracy: 0.5964 - val_loss: 1.2977 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 491ms/step - accuracy: 0.7031 - loss: 0.8812 - val_accuracy: 0.4308 - val_loss: 2.6735 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 487ms/step - accuracy: 0.7204 - loss: 0.8597 - val_accuracy: 0.4692 - val_loss: 1.9158 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 489ms/step - accuracy: 0.7125 - loss: 0.8469 - val_accuracy: 0.5615 - val_loss: 1.4161 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 26.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi pakai test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loss, accuracy = model7.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaIvpwYgk1la",
        "outputId": "42d4b864-342e-495c-fd5b-dc527770d062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1950 images belonging to 13 classes.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.6031 - loss: 1.1791\n",
            "Test Accuracy: 64.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# --- Parameter Dasar ---\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 13\n",
        "L2_LAMBDA = 0.0005\n",
        "\n",
        "# --- Data Augmentation Layer ---\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomContrast(0.2)\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "# --- Fungsi Membangun Model CNN dengan L2 Regularization dan SpatialDropout2D ---\n",
        "def build_model8_regularized_cnn(input_shape, num_classes, data_augmentation_layer, l2_lambda):\n",
        "    inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "    x = data_augmentation_layer(inputs)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(l2_lambda), name=\"conv1a\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn1a\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu1a\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "    x = layers.SpatialDropout2D(0.25, name=\"spatial_drop1\")(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(l2_lambda), name=\"conv2a\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn2a\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu2a\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "    x = layers.SpatialDropout2D(0.25, name=\"spatial_drop2\")(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(l2_lambda), name=\"conv3a\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn3a\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu3a\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool3\")(x)\n",
        "    x = layers.SpatialDropout2D(0.3, name=\"spatial_drop3\")(x)\n",
        "\n",
        "    # Fully Connected Head\n",
        "    x = layers.Flatten(name=\"flatten\")(x)\n",
        "    x = layers.Dense(256, kernel_regularizer=l2(l2_lambda), name=\"dense1\")(x)\n",
        "    x = layers.BatchNormalization(name=\"bn_dense1\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu_dense1\")(x)\n",
        "    x = layers.Dropout(0.5, name=\"drop_dense1\")(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', name=\"output_layer\")(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name=\"model8_regularized_cnn\")\n",
        "    return model\n",
        "\n",
        "model8 = build_model8_regularized_cnn(input_shape, num_classes, data_augmentation, L2_LAMBDA)\n",
        "\n",
        "# --- Kompilasi Model ---\n",
        "initial_learning_rate = 1e-3\n",
        "optimizer = optimizers.Adam(learning_rate=initial_learning_rate)\n",
        "\n",
        "model8.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model8.summary()\n",
        "\n",
        "# --- Callbacks ---\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=7,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks_list = [early_stopping, reduce_lr]\n",
        "\n",
        "# --- Training Model ---\n",
        "epochs = 15\n",
        "print(\"Memulai training model8 (Regularized CNN)...\")\n",
        "history = model8.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks_list\n",
        ")"
      ],
      "metadata": {
        "id": "SrDonfy5Tpo5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "257d045e-dad5-4063-8a9f-8c97d1f5cccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model8_regularized_cnn\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model8_regularized_cnn\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1a (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn1a (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu1a (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_drop1                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2a (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn2a (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu2a (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_drop2                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3a (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn3a (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu3a (\u001b[38;5;33mActivation\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_drop3                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m25,690,368\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn_dense1 (\u001b[38;5;33mBatchNormalization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu_dense1 (\u001b[38;5;33mActivation\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop_dense1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │         \u001b[38;5;34m3,341\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn1a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu1a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_drop1                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn2a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu2a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_drop2                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn3a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu3a (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_drop3                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,368</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ relu_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,341</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,788,877\u001b[0m (98.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,788,877</span> (98.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,787,917\u001b[0m (98.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,787,917</span> (98.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai training model8 (Regularized CNN)...\n",
            "Epoch 1/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 414ms/step - accuracy: 0.2225 - loss: 3.2780 - val_accuracy: 0.3528 - val_loss: 2.5375 - learning_rate: 0.0010\n",
            "Epoch 2/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 416ms/step - accuracy: 0.3164 - loss: 2.5903 - val_accuracy: 0.4092 - val_loss: 2.2864 - learning_rate: 0.0010\n",
            "Epoch 3/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 416ms/step - accuracy: 0.3376 - loss: 2.4837 - val_accuracy: 0.3995 - val_loss: 2.2887 - learning_rate: 0.0010\n",
            "Epoch 4/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 411ms/step - accuracy: 0.3530 - loss: 2.4361 - val_accuracy: 0.4031 - val_loss: 2.2665 - learning_rate: 0.0010\n",
            "Epoch 5/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 412ms/step - accuracy: 0.3546 - loss: 2.4611 - val_accuracy: 0.4005 - val_loss: 2.3226 - learning_rate: 0.0010\n",
            "Epoch 6/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 413ms/step - accuracy: 0.3578 - loss: 2.4690 - val_accuracy: 0.4010 - val_loss: 2.3612 - learning_rate: 0.0010\n",
            "Epoch 7/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 414ms/step - accuracy: 0.3609 - loss: 2.4952 - val_accuracy: 0.4036 - val_loss: 2.4128 - learning_rate: 0.0010\n",
            "Epoch 8/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 413ms/step - accuracy: 0.3562 - loss: 2.5171 - val_accuracy: 0.3226 - val_loss: 2.5721 - learning_rate: 0.0010\n",
            "Epoch 9/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.3620 - loss: 2.5289\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 413ms/step - accuracy: 0.3620 - loss: 2.5289 - val_accuracy: 0.4010 - val_loss: 2.3835 - learning_rate: 0.0010\n",
            "Epoch 10/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 413ms/step - accuracy: 0.3833 - loss: 2.3251 - val_accuracy: 0.4585 - val_loss: 1.9241 - learning_rate: 2.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 411ms/step - accuracy: 0.4182 - loss: 2.0522 - val_accuracy: 0.4605 - val_loss: 1.8682 - learning_rate: 2.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 411ms/step - accuracy: 0.4092 - loss: 2.0436 - val_accuracy: 0.4815 - val_loss: 1.8629 - learning_rate: 2.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 413ms/step - accuracy: 0.4086 - loss: 2.0327 - val_accuracy: 0.4569 - val_loss: 1.8489 - learning_rate: 2.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 411ms/step - accuracy: 0.4127 - loss: 2.0379 - val_accuracy: 0.4774 - val_loss: 1.8172 - learning_rate: 2.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 407ms/step - accuracy: 0.4188 - loss: 2.0008 - val_accuracy: 0.4944 - val_loss: 1.8025 - learning_rate: 2.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 15.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi pakai test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loss, accuracy = model8.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebx1-qOrsAbu",
        "outputId": "dd3e0606-72fe-46fe-9faf-8880ea6d0c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1950 images belonging to 13 classes.\n",
            "\u001b[1m 1/61\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.3125 - loss: 2.1935"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.4678 - loss: 1.8465\n",
            "Test Accuracy: 50.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 9"
      ],
      "metadata": {
        "id": "PvYcGnBiCQqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "model9 = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(256, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOj4QMWBCQEg",
        "outputId": "28cbd2c3-25bc-4002-afef-4b684c563790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcBTazYaCefD",
        "outputId": "67185217-f15b-4d2a-fc1e-d28624049e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15600 images belonging to 13 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model9.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4BlaH6qXCgcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "id": "JfuqvrSDC-5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training model\n",
        "history = model9.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_lCB5FRCwfM",
        "outputId": "05ee9343-4baf-49e0-ec16-bd984b5e9ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 429ms/step - accuracy: 0.2450 - loss: 2.7260 - val_accuracy: 0.3236 - val_loss: 2.1572 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 417ms/step - accuracy: 0.3116 - loss: 2.1283 - val_accuracy: 0.3867 - val_loss: 1.8334 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 418ms/step - accuracy: 0.3477 - loss: 2.0221 - val_accuracy: 0.4544 - val_loss: 1.6140 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 426ms/step - accuracy: 0.3646 - loss: 1.9506 - val_accuracy: 0.4333 - val_loss: 1.7048 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 417ms/step - accuracy: 0.3763 - loss: 1.9117 - val_accuracy: 0.4969 - val_loss: 1.5669 - learning_rate: 1.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 445ms/step - accuracy: 0.4018 - loss: 1.8561 - val_accuracy: 0.4913 - val_loss: 1.5627 - learning_rate: 1.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 471ms/step - accuracy: 0.4089 - loss: 1.8220 - val_accuracy: 0.4800 - val_loss: 1.6258 - learning_rate: 1.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 465ms/step - accuracy: 0.4186 - loss: 1.7546 - val_accuracy: 0.4949 - val_loss: 1.5752 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 459ms/step - accuracy: 0.4195 - loss: 1.7810 - val_accuracy: 0.4533 - val_loss: 1.6189 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 456ms/step - accuracy: 0.4205 - loss: 1.7459 - val_accuracy: 0.5195 - val_loss: 1.5135 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 455ms/step - accuracy: 0.4403 - loss: 1.7161 - val_accuracy: 0.5318 - val_loss: 1.4233 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 461ms/step - accuracy: 0.4529 - loss: 1.6715 - val_accuracy: 0.5641 - val_loss: 1.3496 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 457ms/step - accuracy: 0.4623 - loss: 1.6437 - val_accuracy: 0.5503 - val_loss: 1.3385 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 438ms/step - accuracy: 0.4693 - loss: 1.6164 - val_accuracy: 0.5687 - val_loss: 1.3511 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 437ms/step - accuracy: 0.4819 - loss: 1.6081 - val_accuracy: 0.5713 - val_loss: 1.3124 - learning_rate: 1.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 454ms/step - accuracy: 0.4680 - loss: 1.6275 - val_accuracy: 0.5723 - val_loss: 1.3339 - learning_rate: 1.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 450ms/step - accuracy: 0.4741 - loss: 1.5950 - val_accuracy: 0.5251 - val_loss: 1.4443 - learning_rate: 1.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 457ms/step - accuracy: 0.5004 - loss: 1.5257 - val_accuracy: 0.5759 - val_loss: 1.3295 - learning_rate: 1.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 462ms/step - accuracy: 0.5033 - loss: 1.5167 - val_accuracy: 0.5774 - val_loss: 1.2897 - learning_rate: 1.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 451ms/step - accuracy: 0.5074 - loss: 1.5038 - val_accuracy: 0.5421 - val_loss: 1.3821 - learning_rate: 1.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 453ms/step - accuracy: 0.5107 - loss: 1.4907 - val_accuracy: 0.5774 - val_loss: 1.3215 - learning_rate: 1.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 427ms/step - accuracy: 0.5213 - loss: 1.4560 - val_accuracy: 0.5810 - val_loss: 1.3332 - learning_rate: 1.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 431ms/step - accuracy: 0.5264 - loss: 1.4606 - val_accuracy: 0.5923 - val_loss: 1.2594 - learning_rate: 1.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 453ms/step - accuracy: 0.5356 - loss: 1.4180 - val_accuracy: 0.5287 - val_loss: 1.4292 - learning_rate: 1.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 432ms/step - accuracy: 0.5355 - loss: 1.4148 - val_accuracy: 0.6021 - val_loss: 1.2193 - learning_rate: 1.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 430ms/step - accuracy: 0.5465 - loss: 1.3861 - val_accuracy: 0.6164 - val_loss: 1.1931 - learning_rate: 1.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 437ms/step - accuracy: 0.5473 - loss: 1.3745 - val_accuracy: 0.6395 - val_loss: 1.1240 - learning_rate: 1.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 462ms/step - accuracy: 0.5474 - loss: 1.3778 - val_accuracy: 0.6072 - val_loss: 1.2575 - learning_rate: 1.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 439ms/step - accuracy: 0.5591 - loss: 1.3328 - val_accuracy: 0.6436 - val_loss: 1.1508 - learning_rate: 1.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 453ms/step - accuracy: 0.5651 - loss: 1.3349 - val_accuracy: 0.6333 - val_loss: 1.1459 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 27.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "# Augmentasi\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.15),\n",
        "    layers.RandomZoom(0.15),\n",
        "])\n",
        "\n",
        "model10 = models.Sequential([\n",
        "    layers.Input(shape=(224, 224, 3)),\n",
        "    data_augmentation,\n",
        "\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(13, activation='softmax')\n",
        "])\n",
        "\n",
        "model10.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model10.summary()"
      ],
      "metadata": {
        "id": "KYHjYqqVinFd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "8eb5e442-ec1a-4673-b7c8-3c3bc5681477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m12,845,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │         \u001b[38;5;34m3,341\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,341</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,240,013\u001b[0m (50.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,240,013</span> (50.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,238,541\u001b[0m (50.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,238,541</span> (50.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,472\u001b[0m (5.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> (5.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.3, verbose=1)\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\")\n",
        "\n",
        "# Training model\n",
        "history = model10.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "K0yTkDOKjA3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a23525-f50c-4984-ceff-1034ebb0353b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.2506 - loss: 3.9948"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 410ms/step - accuracy: 0.2507 - loss: 3.9943 - val_accuracy: 0.2210 - val_loss: 3.8170 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.3945 - loss: 3.0664"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 408ms/step - accuracy: 0.3946 - loss: 3.0661 - val_accuracy: 0.3703 - val_loss: 2.8663 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.4228 - loss: 2.6778"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 411ms/step - accuracy: 0.4228 - loss: 2.6777 - val_accuracy: 0.3692 - val_loss: 2.7461 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 403ms/step - accuracy: 0.4381 - loss: 2.5517 - val_accuracy: 0.3415 - val_loss: 2.8539 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 404ms/step - accuracy: 0.4700 - loss: 2.4701 - val_accuracy: 0.3205 - val_loss: 3.1001 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.4780 - loss: 2.5209\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 406ms/step - accuracy: 0.4780 - loss: 2.5210 - val_accuracy: 0.4287 - val_loss: 2.7590 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.5184 - loss: 2.3357"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 407ms/step - accuracy: 0.5185 - loss: 2.3354 - val_accuracy: 0.5021 - val_loss: 2.1919 - learning_rate: 3.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 408ms/step - accuracy: 0.5510 - loss: 2.0113 - val_accuracy: 0.4969 - val_loss: 2.2578 - learning_rate: 3.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 407ms/step - accuracy: 0.5663 - loss: 1.9766 - val_accuracy: 0.5041 - val_loss: 2.2069 - learning_rate: 3.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.5741 - loss: 2.0165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 414ms/step - accuracy: 0.5741 - loss: 2.0166 - val_accuracy: 0.5662 - val_loss: 2.0653 - learning_rate: 3.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 406ms/step - accuracy: 0.5915 - loss: 2.0071 - val_accuracy: 0.4000 - val_loss: 2.8597 - learning_rate: 3.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 403ms/step - accuracy: 0.5843 - loss: 2.0416 - val_accuracy: 0.5364 - val_loss: 2.2084 - learning_rate: 3.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.6010 - loss: 2.0241\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 406ms/step - accuracy: 0.6010 - loss: 2.0242 - val_accuracy: 0.5759 - val_loss: 2.1055 - learning_rate: 3.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.6283 - loss: 1.9381"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 407ms/step - accuracy: 0.6283 - loss: 1.9380 - val_accuracy: 0.5574 - val_loss: 2.0524 - learning_rate: 9.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.6555 - loss: 1.7420"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 408ms/step - accuracy: 0.6555 - loss: 1.7420 - val_accuracy: 0.6328 - val_loss: 1.7807 - learning_rate: 9.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.6640 - loss: 1.6603"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 407ms/step - accuracy: 0.6640 - loss: 1.6603 - val_accuracy: 0.6395 - val_loss: 1.6846 - learning_rate: 9.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 409ms/step - accuracy: 0.6694 - loss: 1.5988 - val_accuracy: 0.6010 - val_loss: 1.7547 - learning_rate: 9.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 409ms/step - accuracy: 0.6740 - loss: 1.5680 - val_accuracy: 0.5713 - val_loss: 1.8883 - learning_rate: 9.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.6786 - loss: 1.5112\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 404ms/step - accuracy: 0.6786 - loss: 1.5112 - val_accuracy: 0.5303 - val_loss: 1.9605 - learning_rate: 9.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 404ms/step - accuracy: 0.6938 - loss: 1.4724 - val_accuracy: 0.5923 - val_loss: 1.7285 - learning_rate: 2.7000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.7023 - loss: 1.4257"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 408ms/step - accuracy: 0.7023 - loss: 1.4257 - val_accuracy: 0.6062 - val_loss: 1.6747 - learning_rate: 2.7000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.7017 - loss: 1.4022"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 407ms/step - accuracy: 0.7017 - loss: 1.4022 - val_accuracy: 0.6323 - val_loss: 1.5900 - learning_rate: 2.7000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 404ms/step - accuracy: 0.7159 - loss: 1.3649 - val_accuracy: 0.6221 - val_loss: 1.6205 - learning_rate: 2.7000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 404ms/step - accuracy: 0.7151 - loss: 1.3514 - val_accuracy: 0.5969 - val_loss: 1.6867 - learning_rate: 2.7000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.7187 - loss: 1.3186\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 404ms/step - accuracy: 0.7187 - loss: 1.3186 - val_accuracy: 0.5954 - val_loss: 1.6738 - learning_rate: 2.7000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.7185 - loss: 1.3100"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 404ms/step - accuracy: 0.7185 - loss: 1.3100 - val_accuracy: 0.6231 - val_loss: 1.5877 - learning_rate: 8.1000e-06\n",
            "Epoch 27/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 408ms/step - accuracy: 0.7261 - loss: 1.3029 - val_accuracy: 0.6087 - val_loss: 1.6341 - learning_rate: 8.1000e-06\n",
            "Epoch 28/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 405ms/step - accuracy: 0.7226 - loss: 1.2877 - val_accuracy: 0.5841 - val_loss: 1.6831 - learning_rate: 8.1000e-06\n",
            "Epoch 29/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.7330 - loss: 1.2596\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 405ms/step - accuracy: 0.7330 - loss: 1.2596 - val_accuracy: 0.6072 - val_loss: 1.6129 - learning_rate: 8.1000e-06\n",
            "Epoch 30/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 403ms/step - accuracy: 0.7290 - loss: 1.2775 - val_accuracy: 0.5979 - val_loss: 1.6388 - learning_rate: 2.4300e-06\n",
            "Epoch 31/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 454ms/step - accuracy: 0.7301 - loss: 1.2524 - val_accuracy: 0.6046 - val_loss: 1.6166 - learning_rate: 2.4300e-06\n",
            "Epoch 32/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.7334 - loss: 1.2587\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 405ms/step - accuracy: 0.7334 - loss: 1.2587 - val_accuracy: 0.6133 - val_loss: 1.5910 - learning_rate: 2.4300e-06\n",
            "Epoch 33/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 404ms/step - accuracy: 0.7370 - loss: 1.2471 - val_accuracy: 0.6113 - val_loss: 1.5893 - learning_rate: 7.2900e-07\n",
            "Epoch 34/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 403ms/step - accuracy: 0.7342 - loss: 1.2531 - val_accuracy: 0.6051 - val_loss: 1.6112 - learning_rate: 7.2900e-07\n"
          ]
        }
      ]
    }
  ]
}