{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-G1RgBaQNpb",
        "outputId": "50f13186-c5e4-4db5-a427-1fcb48d5a40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '1XqTGbpH7OK6cqUIP2_O5JFIUihSQAUND'  # ganti dengan ID milikmu\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', 'dataset_final_split.zip', quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "yR_NoXvdRm_R",
        "outputId": "eb871b52-b266-4f5f-8bf7-a1c46d2d3f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1XqTGbpH7OK6cqUIP2_O5JFIUihSQAUND\n",
            "From (redirected): https://drive.google.com/uc?id=1XqTGbpH7OK6cqUIP2_O5JFIUihSQAUND&confirm=t&uuid=5c0a0c3b-ab34-4636-95db-de4730c2dd4a\n",
            "To: /content/dataset_final_split.zip\n",
            "100%|██████████| 230M/230M [00:01<00:00, 161MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset_final_split.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "wVsfn3m2BARs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('dataset_final_split.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')"
      ],
      "metadata": {
        "id": "4FL91FDiRtkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Pindahkan folder\n",
        "shutil.move('dataset/content/data_final_split', 'data_final_split')\n",
        "\n",
        "# (Opsional) Hapus folder 'dataset/content'\n",
        "shutil.rmtree('dataset')"
      ],
      "metadata": {
        "id": "kGKr0hueRxdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = 'data_final_split'\n",
        "splits = ['train', 'val', 'test']\n",
        "\n",
        "for split in splits:\n",
        "    print(f\"\\n=== {split.upper()} ===\")\n",
        "    split_dir = os.path.join(base_dir, split)\n",
        "    for class_name in os.listdir(split_dir):\n",
        "        class_dir = os.path.join(split_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            n_files = len(os.listdir(class_dir))\n",
        "            print(f\"{class_name}: {n_files} gambar\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cu-jU8wA9ms",
        "outputId": "d1de686f-81df-427e-b95a-df9c10f057a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRAIN ===\n",
            "Daun: 1400 gambar\n",
            "Kardus: 1400 gambar\n",
            "Baterai: 1400 gambar\n",
            "Sterofom: 1400 gambar\n",
            "Logam: 1400 gambar\n",
            "Masker: 1400 gambar\n",
            "Lampu: 1400 gambar\n",
            "Plastik: 1400 gambar\n",
            "Elektronik: 1400 gambar\n",
            "Pakaian: 1400 gambar\n",
            "Sampah Makanan: 1400 gambar\n",
            "Kaca: 1400 gambar\n",
            "Kertas: 1400 gambar\n",
            "\n",
            "=== VAL ===\n",
            "Daun: 300 gambar\n",
            "Kardus: 300 gambar\n",
            "Baterai: 300 gambar\n",
            "Sterofom: 300 gambar\n",
            "Logam: 300 gambar\n",
            "Masker: 300 gambar\n",
            "Lampu: 300 gambar\n",
            "Plastik: 300 gambar\n",
            "Elektronik: 300 gambar\n",
            "Pakaian: 300 gambar\n",
            "Sampah Makanan: 300 gambar\n",
            "Kaca: 300 gambar\n",
            "Kertas: 300 gambar\n",
            "\n",
            "=== TEST ===\n",
            "Daun: 300 gambar\n",
            "Kardus: 300 gambar\n",
            "Baterai: 300 gambar\n",
            "Sterofom: 300 gambar\n",
            "Logam: 300 gambar\n",
            "Masker: 300 gambar\n",
            "Lampu: 300 gambar\n",
            "Plastik: 300 gambar\n",
            "Elektronik: 300 gambar\n",
            "Pakaian: 300 gambar\n",
            "Sampah Makanan: 300 gambar\n",
            "Kaca: 300 gambar\n",
            "Kertas: 300 gambar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELING"
      ],
      "metadata": {
        "id": "UoOHax68S2WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Augmentasi data untuk training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Hanya rescale untuk validasi\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Buat data generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iMDwW1nSoqs",
        "outputId": "8d0342d0-00c2-4573-f0f7-15e248d20777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18200 images belonging to 13 classes.\n",
            "Found 3900 images belonging to 13 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_generator.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uga0iZplBxct",
        "outputId": "a1d29e23-4ade-4d1a-82e2-e9b217355543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Baterai': 0, 'Daun': 1, 'Elektronik': 2, 'Kaca': 3, 'Kardus': 4, 'Kertas': 5, 'Lampu': 6, 'Logam': 7, 'Masker': 8, 'Pakaian': 9, 'Plastik': 10, 'Sampah Makanan': 11, 'Sterofom': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 1"
      ],
      "metadata": {
        "id": "ikSTrNj84YmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Model CNN sederhana\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callback\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "]\n",
        "\n",
        "# Training model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kr60ZCXS460",
        "outputId": "9cb4b043-ba99-4d55-cb29-112fc5a554c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 395ms/step - accuracy: 0.2322 - loss: 2.3242 - val_accuracy: 0.4100 - val_loss: 1.7445 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 375ms/step - accuracy: 0.3831 - loss: 1.8447 - val_accuracy: 0.4651 - val_loss: 1.5977 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 382ms/step - accuracy: 0.4265 - loss: 1.7177 - val_accuracy: 0.4967 - val_loss: 1.5136 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 370ms/step - accuracy: 0.4658 - loss: 1.6263 - val_accuracy: 0.5203 - val_loss: 1.4708 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 369ms/step - accuracy: 0.4772 - loss: 1.5798 - val_accuracy: 0.5118 - val_loss: 1.4761 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 367ms/step - accuracy: 0.5046 - loss: 1.5309 - val_accuracy: 0.5313 - val_loss: 1.4366 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 370ms/step - accuracy: 0.5008 - loss: 1.5108 - val_accuracy: 0.5559 - val_loss: 1.3572 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 371ms/step - accuracy: 0.5205 - loss: 1.4546 - val_accuracy: 0.5374 - val_loss: 1.4343 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 369ms/step - accuracy: 0.5284 - loss: 1.4195 - val_accuracy: 0.5656 - val_loss: 1.3453 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 365ms/step - accuracy: 0.5436 - loss: 1.3871 - val_accuracy: 0.5726 - val_loss: 1.3445 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 365ms/step - accuracy: 0.5528 - loss: 1.3426 - val_accuracy: 0.5782 - val_loss: 1.2669 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 370ms/step - accuracy: 0.5632 - loss: 1.3354 - val_accuracy: 0.5910 - val_loss: 1.2661 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 377ms/step - accuracy: 0.5644 - loss: 1.3168 - val_accuracy: 0.5741 - val_loss: 1.2938 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 378ms/step - accuracy: 0.5715 - loss: 1.2992 - val_accuracy: 0.5956 - val_loss: 1.2765 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 370ms/step - accuracy: 0.5801 - loss: 1.2774 - val_accuracy: 0.5923 - val_loss: 1.2336 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 369ms/step - accuracy: 0.5839 - loss: 1.2630 - val_accuracy: 0.5715 - val_loss: 1.3539 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 366ms/step - accuracy: 0.5841 - loss: 1.2556 - val_accuracy: 0.5913 - val_loss: 1.2373 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 365ms/step - accuracy: 0.5911 - loss: 1.2486 - val_accuracy: 0.6015 - val_loss: 1.2216 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 362ms/step - accuracy: 0.5925 - loss: 1.2315 - val_accuracy: 0.5959 - val_loss: 1.2163 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 365ms/step - accuracy: 0.5916 - loss: 1.2318 - val_accuracy: 0.6223 - val_loss: 1.1821 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 20.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi pakai test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=f'{base_dir}/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSXVcBb-THbk",
        "outputId": "3926019b-010a-4156-92dd-4af204b296c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3900 images belonging to 13 classes.\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.5667 - loss: 1.3087\n",
            "Test Accuracy: 61.49%\n"
          ]
        }
      ]
    }
  ]
}