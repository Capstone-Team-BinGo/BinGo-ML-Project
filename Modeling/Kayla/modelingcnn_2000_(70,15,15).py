# -*- coding: utf-8 -*-
"""ModelingCNN_2000_(70,15,15)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11jRqThnAfqRuvamUEo4pvZuDzUtVh5rC
"""

!pip install gdown
import gdown

file_id = '1XqTGbpH7OK6cqUIP2_O5JFIUihSQAUND'  # ganti dengan ID milikmu
gdown.download(f'https://drive.google.com/uc?id={file_id}', 'dataset_final_split.zip', quiet=False)

import os
import zipfile

with zipfile.ZipFile('dataset_final_split.zip', 'r') as zip_ref:
    zip_ref.extractall('dataset')

import shutil

# Pindahkan folder
shutil.move('dataset/content/data_final_split', 'data_final_split')

# (Opsional) Hapus folder 'dataset/content'
shutil.rmtree('dataset')

base_dir = 'data_final_split'
splits = ['train', 'val', 'test']

for split in splits:
    print(f"\n=== {split.upper()} ===")
    split_dir = os.path.join(base_dir, split)
    for class_name in os.listdir(split_dir):
        class_dir = os.path.join(split_dir, class_name)
        if os.path.isdir(class_dir):
            n_files = len(os.listdir(class_dir))
            print(f"{class_name}: {n_files} gambar")

"""# MODELING"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Augmentasi data untuk training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True
)

# Hanya rescale untuk validasi
val_datagen = ImageDataGenerator(rescale=1./255)

# Buat data generator
train_generator = train_datagen.flow_from_directory(
    directory=f'{base_dir}/train',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    directory=f'{base_dir}/val',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

print(train_generator.class_indices)

"""### MODEL 1"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Model CNN sederhana
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(train_generator.num_classes, activation='softmax')
])

# Kompilasi model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Callback
callbacks = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)
]

# Training model
history = model.fit(
    train_generator,
    epochs=20,
    validation_data=val_generator,
    callbacks=callbacks
)

# Evaluasi pakai test set
test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    directory=f'{base_dir}/test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

loss, accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {accuracy:.2%}")