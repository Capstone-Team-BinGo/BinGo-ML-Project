# -*- coding: utf-8 -*-
"""Modeling [EfficientNetB0] 92%

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ycEgYkuth0BtVPItCPfVQAE9vR-Rjkog
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install gdown
import gdown

file_id = '1owmePKA3WMS7jcw6oY625q59GH3QylYj'
output = 'data_final.zip'
gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)

import zipfile

with zipfile.ZipFile('data_final.zip', 'r') as zip_ref:
    zip_ref.extractall('data_final')
print("âœ… Data berhasil diekstrak ke folder 'data_final/'")

import tensorflow as tf
import numpy as np
import random
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.regularizers import l2

# Paths dataset
train_dir = '/content/data_final/content/data_final_split/train'
val_dir = '/content/data_final/content/data_final_split/val'
test_dir = '/content/data_final/content/data_final_split/test'

# --- Set random seed agar hasil reproducible ---
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
set_seed(42)

# --- Data generators ---
from tensorflow.keras.applications.efficientnet import preprocess_input

train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=30,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    brightness_range=[0.5, 1.5],
    channel_shift_range=20.0,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

# Cek jumlah kelas dari generator latihan
train_gen = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode='categorical',
    shuffle=True,
    seed=42
)

num_classes = train_gen.num_classes # Mendapatkan jumlah kelas secara dinamis

val_gen = val_datagen.flow_from_directory(
    val_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False,
    seed=42
)

test_gen = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224,224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False,
    seed=42
)

print(f"Jumlah kelas yang terdeteksi oleh generator: {num_classes}")
print(f"Mapping kelas ke indeks: {train_gen.class_indices}")

import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import matplotlib.pyplot as plt

# --- Load base model ---
base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
base_model.trainable = False  # Step 1: freeze dulu

# --- Build model ---
inputs = Input(shape=(224, 224, 3))
x = base_model(inputs, training=False)

# Tambahkan Conv2D + MaxPooling setelah pretrained model
x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
outputs = Dense(num_classes, activation='softmax')(x)

model = Model(inputs, outputs)

# --- Compile awal (head training) ---
model.compile(
    optimizer=Adam(learning_rate=1e-3),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# --- Callbacks ---
early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=4, verbose=1)
checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)

callbacks = [early_stop, reduce_lr, checkpoint]

# --- Step 1: Train head saja (fit classifier) ---
history1 = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10,
    callbacks=callbacks
)

# --- Step 2: Fine-tuning EfficientNet (lebih dalam) ---
base_model.trainable = True
for layer in base_model.layers[:50]:
    layer.trainable = False  # Bekukan hanya 50 awal, buka sisanya

# Re-compile dengan learning rate kecil
model.compile(
    optimizer=Adam(learning_rate=1e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# --- Lanjut training ---
history2 = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=50,
    callbacks=callbacks
)

# --- Gabung hasil training ---
def combine_history(h1, h2):
    history = {}
    for key in h1.history:
        history[key] = h1.history[key] + h2.history[key]
    return history

full_history = combine_history(history1, history2)



# --- Plot hasil training ---
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.plot(full_history['accuracy'], label='Train Acc')
plt.plot(full_history['val_accuracy'], label='Val Acc')
plt.title('Accuracy per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(full_history['loss'], label='Train Loss')
plt.plot(full_history['val_loss'], label='Val Loss')
plt.title('Loss per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

# --- Evaluasi di test set ---
test_loss, test_acc = model.evaluate(test_gen)
print(f"\nâœ… Test Accuracy: {test_acc:.4f}")
print(f"ðŸ§ª Test Loss: {test_loss:.4f}")

# --- Prediksi kelas ---
pred_probs = model.predict(test_gen, verbose=1)
y_pred = np.argmax(pred_probs, axis=1)
y_true = test_gen.classes
class_names = list(test_gen.class_indices.keys())

# --- Classification report ---
print("\nðŸ“„ Classification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))

# --- Confusion Matrix ---
cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.xticks(rotation=45)
plt.yticks(rotation=45)
plt.tight_layout()
plt.show()

# --- Load bobot terbaik ---
model.load_weights('best_model.h5')